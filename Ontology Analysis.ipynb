{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2b7363",
   "metadata": {},
   "source": [
    "# Comprehensive Ontology Analysis Overview\n",
    "\n",
    "This document provides a concise overview of the ontology analysis process, explaining each major step in the analysis pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c72ee5",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "In this initial step, we load the ontology data from a JSON file and perform necessary preprocessing. This includes:\n",
    "- Extracting institution and class year information from the filepath\n",
    "- Handling null values in key metrics by filling them with zeros\n",
    "- Ensuring the data is in a suitable format for further analysis\n",
    "\n",
    "This preprocessing helps prevent errors due to missing or inconsistent data and sets the stage for meaningful analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from JSON file and preprocess it.\n",
    "    \"\"\"\n",
    "    # Load the JSON data\n",
    "    df = pd.read_json(file_path)\n",
    "    \n",
    "    # Extract institution and class year from filepath\n",
    "    df['institution'], df['class_year'] = zip(*df['filepath'].apply(extract_info))\n",
    "    \n",
    "    # Handle null values in key metrics\n",
    "    key_metrics = ['class_count', 'object_property_count', 'data_property_count', \n",
    "                   'individual_count', 'axioms', 'logical_axioms']\n",
    "    for metric in key_metrics:\n",
    "        df[metric] = df[metric].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_info(filepath):\n",
    "    \"\"\"\n",
    "    Extract institution and class year from filepath.\n",
    "    \"\"\"\n",
    "    parts = filepath.split('\\\\')\n",
    "    return parts[1], parts[2]\n",
    "\n",
    "# Load the data\n",
    "df = load_and_preprocess_data('data/honest_benchmark_v4.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1e080",
   "metadata": {},
   "source": [
    "## 2. Basic Data Analysis\n",
    "\n",
    "\n",
    "After loading and preprocessing the data, we perform some basic analysis to get an overview of our dataset. This includes:\n",
    "- Counting the total number of ontologies\n",
    "- Identifying the number of unique institutions and class-year combinations\n",
    "- Examining the distribution of ontologies across institutions and class years\n",
    "\n",
    "These basic statistics give us a high-level understanding of the dataset's composition and help identify any initial patterns or imbalances in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_basic_stats(df):\n",
    "    \"\"\"\n",
    "    Display basic statistics about the dataset, including class year counts grouped by institution.\n",
    "    \"\"\"\n",
    "    print(\"Data Overview:\")\n",
    "    print(f\"Total number of ontologies: {len(df)}\")\n",
    "    print(f\"Number of institutions: {df['institution'].nunique()}\")\n",
    "    print(f\"Number of class-year combinations: {df['class_year'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nDistribution of ontologies by institution:\")\n",
    "    display(df['institution'].value_counts())\n",
    "    \n",
    "    print(\"\\nDistribution of ontologies by class year:\")\n",
    "    display(df['class_year'].value_counts())\n",
    "    \n",
    "    print(\"\\nDistribution of class years grouped by institution:\")\n",
    "    grouped = df.groupby(['institution', 'class_year']).size().unstack(fill_value=0)\n",
    "    display(grouped)\n",
    "    \n",
    "    # Optional: Display total counts per institution\n",
    "    print(\"\\nTotal ontologies per institution:\")\n",
    "    display(grouped.sum(axis=1).sort_values(ascending=False))\n",
    "\n",
    "display_basic_stats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ab7cc",
   "metadata": {},
   "source": [
    "## 3. Metrics Analysis\n",
    "\n",
    "Next, we dive deeper into analyzing key metrics of the ontologies. This analysis includes:\n",
    "- Generating summary statistics (mean, median, standard deviation, etc.) for key metrics\n",
    "- Performing correlation analysis between different metrics\n",
    "- Creating distribution plots for each key metric\n",
    "\n",
    "Understanding these metrics and their relationships helps us gauge the complexity and characteristics of the ontologies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_metrics(df, key_metrics):\n",
    "    \"\"\"\n",
    "    Analyze key metrics of the ontologies.\n",
    "    \"\"\"\n",
    "    # Summary statistics\n",
    "    summary = df[key_metrics].describe()\n",
    "    print(\"\\nSummary Statistics of Key Metrics:\")\n",
    "    display(summary)\n",
    "    \n",
    "    # Correlation analysis\n",
    "    correlation = df[key_metrics].corr()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "    plt.title('Correlation Heatmap of Key Metrics')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Distribution plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('Distribution of Key Metrics', fontsize=16)\n",
    "    for i, metric in enumerate(key_metrics):\n",
    "        ax = axes[i // 3, i % 3]\n",
    "        sns.histplot(df[metric], kde=True, ax=ax)\n",
    "        ax.set_title(metric)\n",
    "        ax.set_xlabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "key_metrics = ['class_count', 'object_property_count', 'data_property_count', \n",
    "               'individual_count', 'axioms', 'logical_axioms']\n",
    "analyze_metrics(df, key_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1421f2",
   "metadata": {},
   "source": [
    "## 4. Institution and Class Year Analysis\n",
    "\n",
    "We examine how key metrics vary across different institutions and class years. This analysis provides:\n",
    "- Average metrics by institution\n",
    "- Average metrics by class year\n",
    "- Visualizations of key metrics across institutions and class years\n",
    "\n",
    "This helps identify trends or differences in ontology development practices across different educational settings and over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b29acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_by_institution_and_class_year(df, key_metrics):\n",
    "    \"\"\"\n",
    "    Analyze metrics by institution and class year.\n",
    "    \"\"\"\n",
    "    # Analysis by institution\n",
    "    institution_summary = df.groupby('institution')[key_metrics].mean()\n",
    "    print(\"\\nAverage Metrics by Institution:\")\n",
    "    display(institution_summary)\n",
    "    \n",
    "    # Analysis by class year\n",
    "    class_year_summary = df.groupby('class_year')[key_metrics].mean().sort_index()\n",
    "    print(\"\\nAverage Metrics by Class-Year:\")\n",
    "    display(class_year_summary)\n",
    "    \n",
    "    # Visualize key metrics by institution and class year\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle(\"Key Metrics by Institution and Class-Year\", fontsize=16)\n",
    "    for i, metric in enumerate(key_metrics):\n",
    "        sns.barplot(x='class_year', y=metric, hue='institution', data=df, ax=axes[i//3, i%3])\n",
    "        axes[i//3, i%3].set_title(metric, fontsize=14)\n",
    "        axes[i//3, i%3].set_xticklabels(axes[i//3, i%3].get_xticklabels(), rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_by_institution_and_class_year(df, key_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14f04a",
   "metadata": {},
   "source": [
    "## 5. Complexity Analysis\n",
    "\n",
    "We assess the complexity of ontologies using a composite score derived from key metrics. This analysis includes:\n",
    "- Calculation of a complexity score for each ontology\n",
    "- Visualization of average complexity scores by institution and class year\n",
    "- Identification of the most and least complex ontologies\n",
    "\n",
    "Understanding ontology complexity is crucial for assessing the sophistication of the developed ontologies and identifying potential areas for improvement in ontology design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_complexity(df, key_metrics):\n",
    "    \"\"\"\n",
    "    Analyze the complexity of ontologies.\n",
    "    \"\"\"\n",
    "    # Calculate complexity score\n",
    "    df['complexity_score'] = df[key_metrics].sum(axis=1)\n",
    "    \n",
    "    # Heatmap of average complexity score by institution and class year\n",
    "    pivot_table = df.pivot_table(values='complexity_score', index='institution', columns='class_year', aggfunc='mean')\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot_table, annot=True, cmap='YlOrRd', fmt='.0f')\n",
    "    plt.title('Average Complexity Score by Institution and Class Year')\n",
    "    plt.xlabel('Class Year')\n",
    "    plt.ylabel('Institution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Top and bottom 5 ontologies by complexity\n",
    "    print(\"\\nTop 5 most complex ontologies:\")\n",
    "    display(df.nlargest(5, 'complexity_score')[['institution', 'class_year', 'complexity_score'] + key_metrics])\n",
    "    \n",
    "    print(\"\\nBottom 5 least complex ontologies:\")\n",
    "    display(df.nsmallest(5, 'complexity_score')[['institution', 'class_year', 'complexity_score'] + key_metrics])\n",
    "\n",
    "analyze_complexity(df, key_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d959c",
   "metadata": {},
   "source": [
    "## 6. Error Analysis\n",
    "\n",
    "We analyze errors detected in the ontologies using two different tools: Prock and OOPS. This analysis covers:\n",
    "- Distribution of error counts\n",
    "- Most common types of errors\n",
    "- Average error counts by institution and class year\n",
    "- Correlation between error counts and other metrics\n",
    "\n",
    "Identifying common errors and their patterns helps in improving ontology development practices and enhancing the quality of future ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_errors(df):\n",
    "    \"\"\"\n",
    "    Analyze errors in ontologies.\n",
    "    \"\"\"\n",
    "    # Calculate error counts\n",
    "    df['prock_error_count'] = df['errors_prock'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    df['oops_error_count'] = df['errors_oops'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    \n",
    "    # Visualize error distributions\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    sns.histplot(df['prock_error_count'], ax=ax1, kde=True)\n",
    "    ax1.set_title(\"Distribution of Prock Errors\", fontsize=14)\n",
    "    ax1.set_xlabel(\"Number of Errors\", fontsize=12)\n",
    "    sns.histplot(df['oops_error_count'], ax=ax2, kde=True)\n",
    "    ax2.set_title(\"Distribution of OOPS Errors\", fontsize=14)\n",
    "    ax2.set_xlabel(\"Number of Errors\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Function to safely extract error names\n",
    "    def safe_extract_error_names(errors):\n",
    "        if isinstance(errors, list):\n",
    "            return [error['name'] for error in errors if isinstance(error, dict) and 'name' in error]\n",
    "        return []\n",
    "\n",
    "    # Analyze most common error types\n",
    "    prock_error_types = [name for errors in df['errors_prock'] for name in safe_extract_error_names(errors)]\n",
    "    oops_error_types = [name for errors in df['errors_oops'] for name in safe_extract_error_names(errors)]\n",
    "    \n",
    "    print(\"\\nMost common Prock error types:\")\n",
    "    display(pd.Series(prock_error_types).value_counts().head())\n",
    "    print(\"\\nMost common OOPS error types:\")\n",
    "    display(pd.Series(oops_error_types).value_counts().head(10))\n",
    "    \n",
    "    # Analyze errors by institution and class year\n",
    "    error_metrics = ['prock_error_count', 'oops_error_count']\n",
    "    institution_errors = df.groupby('institution')[error_metrics].mean()\n",
    "    class_year_errors = df.groupby('class_year')[error_metrics].mean().sort_index()\n",
    "    \n",
    "    print(\"\\nAverage Error Counts by Institution:\")\n",
    "    display(institution_errors)\n",
    "    \n",
    "    print(\"\\nAverage Error Counts by Class-Year:\")\n",
    "    display(class_year_errors)\n",
    "\n",
    "    # Additional analysis: Check for entries with no errors\n",
    "    no_errors = df[(df['prock_error_count'] == 0) & (df['oops_error_count'] == 0)]\n",
    "    print(f\"\\nNumber of ontologies with no errors: {len(no_errors)}\")\n",
    "    print(f\"Percentage of ontologies with no errors: {(len(no_errors) / len(df)) * 100:.2f}%\")\n",
    "\n",
    "    # Correlation between error counts and other metrics\n",
    "    error_correlation = df[['prock_error_count', 'oops_error_count', 'class_count', 'object_property_count', 'data_property_count', 'individual_count', 'axioms', 'logical_axioms']].corr()\n",
    "    print(\"\\nCorrelation between error counts and other metrics:\")\n",
    "    display(error_correlation[['prock_error_count', 'oops_error_count']])\n",
    "\n",
    "# Run the analysis\n",
    "analyze_errors(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc505c02",
   "metadata": {},
   "source": [
    "## 7. DL Expressivity Analysis\n",
    "\n",
    "We examine the Description Logic (DL) expressivity of the ontologies. This analysis includes:\n",
    "- Presence and count of different DL features across ontologies\n",
    "- Visualization of feature presence and counts\n",
    "- Analysis of feature usage by institution and class year\n",
    "\n",
    "Understanding DL expressivity provides insights into the complexity and capabilities of the developed ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_dl_expressivity(df):\n",
    "    \"\"\"\n",
    "    Analyze DL expressivity of ontologies.\n",
    "    \"\"\"\n",
    "    # Define OWL feature descriptions\n",
    "    feature_descriptions = {\n",
    "        'A': 'Asymmetric properties',\n",
    "        'C': 'Complex class constructors',\n",
    "        'D': 'Datatype properties',\n",
    "        'E': 'Existential restrictions',\n",
    "        'F': 'Functional properties',\n",
    "        'H': 'Role hierarchies',\n",
    "        'I': 'Inverse properties',\n",
    "        'N': 'Cardinality restrictions',\n",
    "        'O': 'Nominals',\n",
    "        'Q': 'Qualified cardinality restrictions',\n",
    "        'R': 'Role constructors',\n",
    "        'X': 'Reflexive properties',\n",
    "        'Y': 'Irreflexive properties',\n",
    "        'S': 'Symmetric properties',\n",
    "        'T': 'Transitive properties',\n",
    "        'U': 'Union of concepts'\n",
    "    }\n",
    "    \n",
    "    # Extract DL expressivity details\n",
    "    df['expressivity_details'] = df['dl_expressivity_details'].apply(\n",
    "        lambda x: {item['feature']: item for item in x} if isinstance(x, list) else {}\n",
    "    )\n",
    "    \n",
    "    # Analyze feature presence and count\n",
    "    feature_presence = {feature: sum(1 for details in df['expressivity_details'] if details.get(feature, {}).get('present') == 1) for feature in feature_descriptions}\n",
    "    feature_count = {feature: sum(details.get(feature, {}).get('feature_count', 0) for details in df['expressivity_details']) for feature in feature_descriptions}\n",
    "    \n",
    "    # Plot overall feature presence\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sorted_features = sorted(feature_presence.items(), key=lambda x: x[1], reverse=True)\n",
    "    presence_data = [x[1] for x in sorted_features]\n",
    "    feature_labels = [x[0] for x in sorted_features]\n",
    "    plt.bar(feature_labels, presence_data)\n",
    "    plt.title(\"Overall Presence of DL Expressivity Features Across Ontologies\", fontsize=16)\n",
    "    plt.xlabel(\"DL Expressivity Feature\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Ontologies\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display tabular view for feature presence\n",
    "    presence_table = pd.DataFrame({\n",
    "        'Feature': feature_labels,\n",
    "        'Presence': presence_data,\n",
    "        'Description': [feature_descriptions[f] for f in feature_labels]\n",
    "    })\n",
    "    print(\"Overall Presence of DL Expressivity Features:\")\n",
    "    display(presence_table)\n",
    "\n",
    "analyze_dl_expressivity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2db8d",
   "metadata": {},
   "source": [
    "## 8. Competency Questions Analysis\n",
    "\n",
    "We analyze the competency questions associated with each ontology. This analysis covers:\n",
    "- Number of competency questions per ontology\n",
    "- Average question length\n",
    "- Most common words in competency questions\n",
    "- Analysis of questions by institution and class year\n",
    "\n",
    "Competency questions are crucial for understanding the intended use and coverage of ontologies, making this analysis valuable for assessing ontology quality and relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03997fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_competency_questions(df):\n",
    "    \"\"\"\n",
    "    Analyze competency questions in ontologies.\n",
    "    \"\"\"\n",
    "    # Clean the competency_questions column\n",
    "    df['competency_questions'] = df['competency_questions'].apply(\n",
    "        lambda x: [str(q) for q in x] if isinstance(x, list) else [str(x)] if isinstance(x, str) else []\n",
    "    )\n",
    "    \n",
    "    # Analyze competency questions\n",
    "    df['word_freq'], df['avg_question_length'], df['question_count'] = zip(*df['competency_questions'].apply(\n",
    "        lambda questions: (\n",
    "            Counter([word.lower() for question in questions for word in word_tokenize(question) if word.isalnum() and word.lower() not in stopwords.words('english')]),\n",
    "            sum(len(question.split()) for question in questions) / len(questions) if questions else 0,\n",
    "            len(questions)\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Analysis by institution and class year\n",
    "    institution_class_year_analysis = df.groupby(['institution', 'class_year']).agg({\n",
    "        'question_count': ['sum', 'mean', 'size'],\n",
    "        'avg_question_length': 'mean',\n",
    "        'word_freq': lambda x: ', '.join([f\"{word} ({count})\" for word, count in sum(x, Counter()).most_common(5)])\n",
    "    }).reset_index()\n",
    "    \n",
    "    institution_class_year_analysis.columns = ['institution', 'class_year', 'total_questions', 'avg_questions_per_entry', 'num_ontologies', 'avg_question_length', 'top_words']\n",
    "    institution_class_year_analysis['norm_question_count'] = institution_class_year_analysis['total_questions'] / institution_class_year_analysis['num_ontologies']\n",
    "    \n",
    "    print(\"\\nAnalysis of Competency Questions by Institution and Class Year:\")\n",
    "    display(institution_class_year_analysis)\n",
    "    \n",
    "    # Updated table: Institution statistics including average, total questions, and number of ontologies\n",
    "    institution_stats = df.groupby('institution').agg({\n",
    "        'question_count': ['mean', 'sum', 'size']\n",
    "    }).reset_index()\n",
    "    institution_stats.columns = ['Institution', 'Average Competency Questions', 'Total Competency Questions', 'Number of Ontologies']\n",
    "    institution_stats = institution_stats.sort_values('Average Competency Questions', ascending=False)\n",
    "    institution_stats['Average Competency Questions'] = institution_stats['Average Competency Questions'].round(2)\n",
    "    \n",
    "    print(\"\\nInstitution Statistics for Competency Questions:\")\n",
    "    display(institution_stats)\n",
    "    \n",
    "    # Visualizations\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for institution in df['institution'].unique():\n",
    "        data = institution_class_year_analysis[institution_class_year_analysis['institution'] == institution]\n",
    "        plt.plot(data['class_year'], data['norm_question_count'], marker='o', label=institution)\n",
    "    plt.title('Normalized Number of Competency Questions by Institution and Class Year')\n",
    "    plt.xlabel('Class Year')\n",
    "    plt.ylabel('Average Number of Questions per Ontology')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print overall statistics\n",
    "    total_questions = df['question_count'].sum()\n",
    "    total_ontologies = len(df)\n",
    "    avg_questions_per_ontology = total_questions / total_ontologies\n",
    "    overall_avg_length = df['avg_question_length'].mean()\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Total number of competency questions: {total_questions}\")\n",
    "    print(f\"Total number of ontologies: {total_ontologies}\")\n",
    "    print(f\"Average number of questions per ontology: {avg_questions_per_ontology:.2f}\")\n",
    "    print(f\"Overall average question length: {overall_avg_length:.2f} words\")\n",
    "    \n",
    "    # Find most common words across all competency questions\n",
    "    all_word_freq = Counter()\n",
    "    for freq in df['word_freq']:\n",
    "        all_word_freq.update(freq)\n",
    "    \n",
    "    print(\"\\nTop 10 most common words in competency questions:\")\n",
    "    for word, count in all_word_freq.most_common(10):\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "analyze_competency_questions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d19e0e",
   "metadata": {},
   "source": [
    "## 9. Outlier Analysis\n",
    "\n",
    "We identify and analyze outliers in the dataset, particularly focusing on ontologies with an unusual number of competency questions. This includes:\n",
    "- Identification of outliers based on the number of competency questions\n",
    "- Detailed examination of outlier ontologies\n",
    "- Visualization of outlier distribution\n",
    "\n",
    "Analyzing outliers can reveal exceptional cases that might provide insights into best practices or areas needing improvement in ontology development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_outliers(group):\n",
    "    \"\"\"\n",
    "    Find outliers in a group based on the number of competency questions.\n",
    "    \"\"\"\n",
    "    q1 = group['question_count'].quantile(0.25)\n",
    "    q3 = group['question_count'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return group[group['question_count'] > upper_bound].sort_values('question_count', ascending=False)\n",
    "\n",
    "def analyze_outliers(df):\n",
    "    \"\"\"\n",
    "    Analyze outliers in the dataset.\n",
    "    \"\"\"\n",
    "    # Find outliers for each institution\n",
    "    outliers = df.groupby('institution').apply(find_outliers).reset_index(drop=True)\n",
    "    \n",
    "    # Display outliers for each institution\n",
    "    for institution in outliers['institution'].unique():\n",
    "        print(f\"\\nOutliers for {institution}:\")\n",
    "        inst_outliers = outliers[outliers['institution'] == institution]\n",
    "        for _, row in inst_outliers.iterrows():\n",
    "            print(f\"Class Year: {row['class_year']}\")\n",
    "            print(f\"Domain: {row['domain']}\")\n",
    "            print(f\"Number of Competency Questions: {row['question_count']}\")\n",
    "            print(\"Sample of Competency Questions:\")\n",
    "            for q in row['competency_questions'][:5]:  # Display first 5 questions\n",
    "                print(f\"- {q}\")\n",
    "            print()\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    print(\"\\nOutlier Statistics:\")\n",
    "    print(f\"Total number of outliers: {len(outliers)}\")\n",
    "    print(\"\\nNumber of outliers per institution:\")\n",
    "    display(outliers['institution'].value_counts())\n",
    "    print(\"\\nAverage number of competency questions in outliers:\")\n",
    "    display(outliers.groupby('institution')['question_count'].mean())\n",
    "    \n",
    "    # Visualize outliers\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='institution', y='question_count', data=df)\n",
    "    plt.title('Distribution of Competency Question Counts by Institution')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize outliers (only outliers)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(x='institution', y='question_count', data=outliers)\n",
    "    plt.title('Outliers: Number of Competency Questions by Institution')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "analyze_outliers(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef893a15",
   "metadata": {},
   "source": [
    "## 10. Trend Analysis\n",
    "\n",
    "We examine trends in ontology development over time. This analysis covers:\n",
    "- Changes in key metrics over years\n",
    "- Trends by institution\n",
    "- Visualization of metric trends\n",
    "\n",
    "Understanding these trends helps in identifying improvements or changes in ontology development practices over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_trends(df):\n",
    "    \"\"\"\n",
    "    Analyze trends in the dataset over time.\n",
    "    \"\"\"\n",
    "    # Extract year from class_year and create a new 'year' column\n",
    "    df['year'] = df['class_year'].str.extract('(\\d{4})').astype(int)\n",
    "    \n",
    "    # Sort the DataFrame by year in ascending order\n",
    "    df = df.sort_values('year')\n",
    "    \n",
    "    # List of key metrics\n",
    "    key_metrics = ['class_count', 'object_property_count', 'data_property_count', 'individual_count', 'axioms', 'logical_axioms']\n",
    "    \n",
    "    # Trend Analysis\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for institution in df['institution'].unique():\n",
    "        inst_data = df[df['institution'] == institution]\n",
    "        for metric in key_metrics:\n",
    "            sns.lineplot(x='year', y=metric, data=inst_data, marker='o', label=f\"{institution} - {metric}\")\n",
    "    \n",
    "    plt.title(\"Trends in Metrics Over Years by Institution\", fontsize=16)\n",
    "    plt.xlabel(\"Year\", fontsize=12)\n",
    "    plt.ylabel(\"Average Value\", fontsize=12)\n",
    "    plt.legend(title=\"Institution - Metric\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Tabular view for trend analysis\n",
    "    trend_table = df.groupby(['year', 'institution'])[key_metrics].mean().reset_index()\n",
    "    print(\"Trend Analysis - Average Metrics by Year and Institution:\")\n",
    "    display(trend_table)\n",
    "\n",
    "analyze_trends(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad71048",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Statistical Analysis\n",
    "\n",
    "We perform more advanced statistical analyses to uncover significant patterns or differences in the data. This includes:\n",
    "- Correlation analysis between numerical metrics\n",
    "- T-tests to compare metrics between institutions\n",
    "- ANOVA to compare metrics across years\n",
    "\n",
    "These statistical tests help in identifying significant differences or relationships that might not be apparent from descriptive statistics alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfbab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def perform_statistical_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis on the dataset.\n",
    "    \"\"\"\n",
    "    key_metrics = ['class_count', 'object_property_count', 'data_property_count', 'individual_count', 'axioms', 'logical_axioms']\n",
    "    \n",
    "    # Correlation analysis\n",
    "    correlation_matrix = df[key_metrics].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "    plt.title(\"Correlation Matrix of Numerical Metrics\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    display(correlation_matrix)\n",
    "    \n",
    "    # T-tests to compare metrics between institutions\n",
    "    print(\"\\nT-test Results - Comparing Metrics Between Institutions:\")\n",
    "    t_test_results = []\n",
    "    for metric in key_metrics:\n",
    "        tu_group = df[df['institution'] == 'TU'][metric]\n",
    "        wu_group = df[df['institution'] == 'WU'][metric]\n",
    "        t_stat, p_value = stats.ttest_ind(tu_group, wu_group)\n",
    "        t_test_results.append({'Metric': metric, 't-statistic': t_stat, 'p-value': p_value})\n",
    "        print(f\"{metric}: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\")\n",
    "    \n",
    "    # ANOVA to compare metrics across years\n",
    "    print(\"\\nANOVA Results - Comparing Metrics Across Years:\")\n",
    "    anova_results = []\n",
    "    for metric in key_metrics:\n",
    "        years = df['year'].unique()\n",
    "        year_groups = [df[df['year'] == y][metric] for y in years]\n",
    "        f_statistic, p_value = stats.f_oneway(*year_groups)\n",
    "        anova_results.append({'Metric': metric, 'F-statistic': f_statistic, 'p-value': p_value})\n",
    "        print(f\"{metric}: F-statistic = {f_statistic:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "perform_statistical_analysis(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654679a",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Quality Assessment\n",
    "\n",
    "We assess the overall quality of ontologies based on various metrics and error counts. This assessment includes:\n",
    "- Calculation of a quality score for each ontology\n",
    "- Identification of top and bottom ontologies by quality\n",
    "- Analysis of quality scores by institution and class year\n",
    "\n",
    "This quality assessment provides a holistic view of ontology development outcomes and helps identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assess_quality(df):\n",
    "    \"\"\"\n",
    "    Assess the quality of ontologies based on various metrics.\n",
    "    \"\"\"\n",
    "    # Calculate a simple quality score based on key metrics and error counts\n",
    "    df['quality_score'] = (\n",
    "        df['class_count'] + \n",
    "        df['object_property_count'] + \n",
    "        df['data_property_count'] + \n",
    "        df['individual_count'] + \n",
    "        df['axioms'] / 10  # Normalized to give less weight to axioms\n",
    "    ) / (1 + np.log1p(df['prock_error_count'] + df['oops_error_count']))  # Log to reduce impact of errors\n",
    "    \n",
    "    # Visualize quality score distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df['quality_score'], kde=True)\n",
    "    plt.title('Distribution of Quality Scores')\n",
    "    plt.xlabel('Quality Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # Top and bottom 10 ontologies by quality score\n",
    "    print(\"\\nTop 10 ontologies by quality score:\")\n",
    "    display(df.nlargest(10, 'quality_score')[['institution', 'class_year', 'domain', 'quality_score']])\n",
    "    \n",
    "    print(\"\\nBottom 10 ontologies by quality score:\")\n",
    "    display(df.nsmallest(10, 'quality_score')[['institution', 'class_year', 'domain', 'quality_score']])\n",
    "    \n",
    "    # Average quality score by institution and class year\n",
    "    quality_by_inst_year = df.groupby(['institution', 'class_year'])['quality_score'].mean().unstack()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(quality_by_inst_year, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "    plt.title('Average Quality Score by Institution and Class Year')\n",
    "    plt.show()\n",
    "\n",
    "assess_quality(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfec54",
   "metadata": {},
   "source": [
    "\n",
    "## 13. Domain Analysis\n",
    "\n",
    "We analyze the different domains covered by the ontologies in our dataset. This analysis includes:\n",
    "- Identification of most common domains\n",
    "- Analysis of domain distribution across institutions\n",
    "- Visualization of domain diversity\n",
    "\n",
    "Understanding the range and distribution of domains helps in assessing the breadth of ontology development efforts and identifying potential gaps or areas of focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540632a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def analyze_domains(df):\n",
    "    \"\"\"\n",
    "    Analyze the domains of ontologies with wordcloud and detailed statistics.\n",
    "    \"\"\"\n",
    "    # Function to get domain frequency\n",
    "    def get_domain_frequency(data):\n",
    "        return Counter(data['domain'].str.lower().dropna())\n",
    "\n",
    "    # Preprocess function to make text case-insensitive\n",
    "    def preprocess_text(text):\n",
    "        return ' '.join(text.str.lower().dropna())\n",
    "\n",
    "    # Overall Domain Frequency\n",
    "    overall_freq = get_domain_frequency(df)\n",
    "    print(\"\\nOverall Domain Frequency:\")\n",
    "    print(pd.DataFrame.from_dict(overall_freq, orient='index', columns=['Count']).sort_values('Count', ascending=False).head(20))\n",
    "\n",
    "    # Plot overall wordcloud\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(preprocess_text(df['domain']))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title('Overall Wordcloud of Ontology Domains')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Analysis by Institution\n",
    "    institutions = sorted(df['institution'].unique())\n",
    "    fig_institution, axes_institution = plt.subplots(1, len(institutions), figsize=(20, 8))\n",
    "    fig_institution.suptitle('Word Clouds of Ontology Domains by Institution', fontsize=16)\n",
    "    print(\"\\nDomain Frequencies by Institution:\")\n",
    "    for i, institution in enumerate(institutions):\n",
    "        institution_data = df[df['institution'] == institution]\n",
    "        text = preprocess_text(institution_data['domain'])\n",
    "        \n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "        \n",
    "        ax = axes_institution[i] if len(institutions) > 1 else axes_institution\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.set_title(f'Institution: {institution}')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Display tabular data\n",
    "        domain_freq = get_domain_frequency(institution_data)\n",
    "        print(f\"\\nInstitution: {institution}\")\n",
    "        print(pd.DataFrame.from_dict(domain_freq, orient='index', columns=['Count']).sort_values('Count', ascending=False).head(10))\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # Analysis by Class-Year\n",
    "    class_years = sorted(df['class_year'].unique())\n",
    "    n_class_years = len(class_years)\n",
    "    fig_class_year, axes_class_year = plt.subplots(2, (n_class_years + 1) // 2, figsize=(20, 12))\n",
    "    fig_class_year.suptitle('Word Clouds of Ontology Domains by Class-Year', fontsize=16)\n",
    "    print(\"\\nDomain Frequencies by Class-Year:\")\n",
    "    for i, class_year in enumerate(class_years):\n",
    "        class_year_data = df[df['class_year'] == class_year]\n",
    "        text = preprocess_text(class_year_data['domain'])\n",
    "        \n",
    "        wordcloud = WordCloud(width=400, height=200, background_color='white').generate(text)\n",
    "        \n",
    "        ax = axes_class_year[i // ((n_class_years + 1) // 2), i % ((n_class_years + 1) // 2)]\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.set_title(f'Class-Year: {class_year}')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Display tabular data\n",
    "        domain_freq = get_domain_frequency(class_year_data)\n",
    "        print(f\"\\nClass-Year: {class_year}\")\n",
    "        print(pd.DataFrame.from_dict(domain_freq, orient='index', columns=['Count']).sort_values('Count', ascending=False).head(10))\n",
    "    \n",
    "    # Remove any unused subplots for class-years\n",
    "    for j in range(i + 1, (n_class_years + 1) // 2 * 2):\n",
    "        fig_class_year.delaxes(axes_class_year[j // ((n_class_years + 1) // 2), j % ((n_class_years + 1) // 2)])\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # Additional bar plots from the original code\n",
    "    # Count occurrences of each domain\n",
    "    domain_counts = df['domain'].value_counts()\n",
    "    \n",
    "    # Plot top 20 domains\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    domain_counts.head(20).plot(kind='bar')\n",
    "    plt.title('Top 20 Ontology Domains')\n",
    "    plt.xlabel('Domain')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print domain statistics\n",
    "    print(f\"\\nTotal number of unique domains: {len(domain_counts)}\")\n",
    "    print(\"\\nTop 10 domains:\")\n",
    "    display(domain_counts.head(10))\n",
    "    \n",
    "    # Analyze domains by institution\n",
    "    domains_by_institution = df.groupby('institution')['domain'].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    domains_by_institution.plot(kind='bar', stacked=True)\n",
    "    plt.title('Domain Distribution by Institution')\n",
    "    plt.xlabel('Institution')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Domain', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "analyze_domains(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ce6a5",
   "metadata": {},
   "source": [
    "\n",
    "## 14. Conclusions and Recommendations\n",
    "\n",
    "Finally, we draw conclusions from our analysis and provide recommendations for improving ontology development practices. This section summarizes key findings from the analysis and offers actionable recommendations for enhancing ontology development processes, improving quality, and addressing identified issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1839496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_conclusions(df):\n",
    "    \"\"\"\n",
    "    Draw conclusions and make recommendations based on the analysis.\n",
    "    \"\"\"\n",
    "    print(\"Conclusions and Recommendations:\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n1. Overall Statistics:\")\n",
    "    print(f\"   - Total number of ontologies: {len(df)}\")\n",
    "    print(f\"   - Number of institutions: {df['institution'].nunique()}\")\n",
    "    print(f\"   - Number of class years: {df['class_year'].nunique()}\")\n",
    "    \n",
    "    # Complexity\n",
    "    print(\"\\n2. Ontology Complexity:\")\n",
    "    avg_complexity = df['complexity_score'].mean()\n",
    "    print(f\"   - Average complexity score: {avg_complexity:.2f}\")\n",
    "    print(\"   - Recommendation: Focus on reducing complexity in future ontologies while maintaining expressiveness.\")\n",
    "    \n",
    "    # Error analysis\n",
    "    print(\"\\n3. Error Analysis:\")\n",
    "    avg_prock_errors = df['prock_error_count'].mean()\n",
    "    avg_oops_errors = df['oops_error_count'].mean()\n",
    "    print(f\"   - Average Prock errors per ontology: {avg_prock_errors:.2f}\")\n",
    "    print(f\"   - Average OOPS errors per ontology: {avg_oops_errors:.2f}\")\n",
    "    print(\"   - Recommendation: Implement stricter quality control measures to reduce the number of errors.\")\n",
    "    \n",
    "    # Competency questions\n",
    "    print(\"\\n4. Competency Questions:\")\n",
    "    avg_questions = df['question_count'].mean()\n",
    "    print(f\"   - Average number of competency questions per ontology: {avg_questions:.2f}\")\n",
    "    print(\"   - Recommendation: Encourage the creation of more comprehensive sets of competency questions to guide ontology development.\")\n",
    "    \n",
    "    # Domain diversity\n",
    "    print(\"\\n5. Domain Diversity:\")\n",
    "    num_domains = df['domain'].nunique()\n",
    "    print(f\"   - Number of unique domains: {num_domains}\")\n",
    "    print(\"   - Recommendation: Explore opportunities to develop ontologies in underrepresented domains.\")\n",
    "    \n",
    "    # Trends\n",
    "    print(\"\\n6. Trends:\")\n",
    "    recent_year = df['year'].max()\n",
    "    recent_complexity = df[df['year'] == recent_year]['complexity_score'].mean()\n",
    "    overall_complexity = df['complexity_score'].mean()\n",
    "    if recent_complexity > overall_complexity:\n",
    "        trend = \"increasing\"\n",
    "    else:\n",
    "        trend = \"decreasing\"\n",
    "    print(f\"   - Ontology complexity is {trend} over time.\")\n",
    "    print(\"   - Recommendation: Continue monitoring trends and adjust teaching methods accordingly.\")\n",
    "    \n",
    "draw_conclusions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the entire analysis\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_and_preprocess_data('data/honest_benchmark_v4.json')\n",
    "    display_basic_stats(df)\n",
    "    analyze_metrics(df, key_metrics)\n",
    "    analyze_by_institution_and_class_year(df, key_metrics)\n",
    "    analyze_complexity(df, key_metrics)\n",
    "    analyze_errors(df)\n",
    "    analyze_dl_expressivity(df)\n",
    "    analyze_competency_questions(df)\n",
    "    analyze_outliers(df)\n",
    "    analyze_trends(df)\n",
    "    perform_statistical_analysis(df)\n",
    "    assess_quality(df)\n",
    "    analyze_domains(df)\n",
    "    draw_conclusions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5d7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
